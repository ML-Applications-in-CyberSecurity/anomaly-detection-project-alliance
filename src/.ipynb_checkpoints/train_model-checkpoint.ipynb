{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9cba8b9",
   "metadata": {},
   "source": [
    "### 🧩 Imports\n",
    "\n",
    "Import all the necessary libraries:\n",
    "- `json` for reading/writing JSON files.\n",
    "- `pandas` and `numpy` for data manipulation.\n",
    "- `random` for generating random synthetic data.\n",
    "- `IsolationForest` from `sklearn` for anomaly detection.\n",
    "- `joblib` for saving the trained model."
   ]
  },
  {
   "cell_type": "code",
   "id": "a807fa48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T07:59:26.572065Z",
     "start_time": "2025-07-03T07:59:18.511696Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "66939a62",
   "metadata": {},
   "source": [
    "### 📊 Generate Dataset\n",
    "\n",
    "Create synthetic \"normal\" network traffic data to train an anomaly detection model. Each sample includes:\n",
    "\n",
    "- `src_port`: randomly selected from common service ports.\n",
    "- `dst_port`: a random high port number.\n",
    "- `packet_size`: typical packet sizes.\n",
    "- `duration_ms`: duration of the communication.\n",
    "- `protocol`: randomly selected between TCP and UDP.\n",
    "\n",
    "This data is saved to `training_data.json` for future use."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"ds\")",
   "id": "d741c0de8bafea95"
  },
  {
   "cell_type": "code",
   "id": "870cc066",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T07:59:42.213728Z",
     "start_time": "2025-07-03T07:59:41.655600Z"
    }
   },
   "source": [
    "COMMON_PORTS = [80, 443, 22, 8080]\n",
    "\n",
    "def generate_normal_data():\n",
    "    return {\n",
    "        \"src_port\": random.choice(COMMON_PORTS),\n",
    "        \"dst_port\": random.randint(1024, 65535),\n",
    "        \"packet_size\": random.randint(100, 1500),\n",
    "        \"duration_ms\": random.randint(50, 500),\n",
    "        \"protocol\": random.choice([\"TCP\", \"UDP\"])\n",
    "    }\n",
    "\n",
    "dataset = [generate_normal_data() for _ in range(1000)]\n",
    "\n",
    "with open(\"../dataset/training_data.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/training_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 14\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m      5\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msrc_port\u001B[39m\u001B[38;5;124m\"\u001B[39m: random\u001B[38;5;241m.\u001B[39mchoice(COMMON_PORTS),\n\u001B[0;32m      6\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdst_port\u001B[39m\u001B[38;5;124m\"\u001B[39m: random\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m1024\u001B[39m, \u001B[38;5;241m65535\u001B[39m),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprotocol\u001B[39m\u001B[38;5;124m\"\u001B[39m: random\u001B[38;5;241m.\u001B[39mchoice([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTCP\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUDP\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     10\u001B[0m     }\n\u001B[0;32m     12\u001B[0m dataset \u001B[38;5;241m=\u001B[39m [generate_normal_data() \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1000\u001B[39m)]\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../dataset/training_data.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     15\u001B[0m     json\u001B[38;5;241m.\u001B[39mdump(dataset, f, indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../dataset/training_data.json'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1dd53134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T07:59:58.106998Z",
     "start_time": "2025-07-03T07:59:58.085173Z"
    }
   },
   "source": [
    "with open(\"./dataset/training_data.json\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "display(df)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/training_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./dataset/training_data.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      2\u001B[0m     raw_data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[0;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(raw_data)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './dataset/training_data.json'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "439e560b",
   "metadata": {},
   "source": [
    "### 🧼 Preprocessing Function\n",
    "\n",
    "Machine learning models like Isolation Forest require **numerical input only**. Any categorical variables, such as the `protocol` column (`TCP`, `UDP`), must be converted into numbers.\n",
    "\n",
    "We handle this with **one-hot encoding**, using `pd.get_dummies`.\n",
    "\n",
    "#### 🛠️ Preprocessing Steps:\n",
    "\n",
    "1. **Identify categorical columns**:\n",
    "   - In our case, the `protocol` column is categorical (`TCP`, `UDP`).\n",
    "\n",
    "2. **Use `pd.get_dummies`**:\n",
    "   - This creates a new binary column for each category.\n",
    "   - For instance:\n",
    "     ```\n",
    "     protocol\n",
    "     ---------\n",
    "     TCP   →   protocol_UDP = 0\n",
    "     UDP   →   protocol_UDP = 1\n",
    "     ```\n",
    "   - Setting `drop_first=True` prevents multicollinearity by dropping the first category (`TCP` here), as it can be inferred from the others.\n",
    "\n",
    "3. **Return a DataFrame with all numerical values**:\n",
    "   - This is ready for model input.\n",
    "\n",
    "> ✅ This preprocessing is essential to avoid errors during training and ensure the model can learn from categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "id": "aae1de67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T07:59:59.889703Z",
     "start_time": "2025-07-03T07:59:59.884367Z"
    }
   },
   "source": [
    "def preprocess_data(df):\n",
    "    #TODO 1: Implement preprocessing steps\n",
    "\n",
    "    return np.array(df)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "7c5bf7fa",
   "metadata": {},
   "source": [
    "### 🤖 Train Isolation Forest\n",
    "\n",
    "The `IsolationForest` algorithm is an unsupervised model used to detect anomalies. It isolates observations by randomly selecting features and splitting values.\n",
    "\n",
    "- `n_estimators=100`: number of trees in the forest.\n",
    "- `contamination=0.01`: assumes 1% of the data is anomalous.\n",
    "- `random_state=42`: ensures reproducibility.\n",
    "\n",
    "The model is trained on the preprocessed numerical dataset."
   ]
  },
  {
   "cell_type": "code",
   "id": "1226cc18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T08:00:01.546814Z",
     "start_time": "2025-07-03T08:00:01.480084Z"
    }
   },
   "source": [
    "model = IsolationForest(contamination=0.1, random_state=42)\n",
    "model.fit()"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "IsolationForest.fit() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m IsolationForest(contamination\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: IsolationForest.fit() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "b3d27677",
   "metadata": {},
   "source": [
    "### 💾 Save Trained Model\n",
    "\n",
    "Save the trained model using `joblib`, which allows for efficient serialization and deserialization. This saved model can be reused later for inference or deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205b791",
   "metadata": {},
   "source": [
    "joblib.dump(model, \"anomaly_model.joblib\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "aca5c30c",
   "metadata": {},
   "source": [
    "# predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd9507",
   "metadata": {},
   "source": [
    "model.predict()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "university",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
